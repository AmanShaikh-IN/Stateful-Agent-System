{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POUXvctgcH3C"
      },
      "source": [
        "# Building Multi-Tool Agent Systems with LangChain, LangGraph and AstraDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuP40sQRcdyb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "g4takLNeS4TC"
      },
      "outputs": [],
      "source": [
        "!pip install -q astrapy langchain-groq langchain-community langchain-core langgraph \\\n",
        "    langchain-text-splitters langchain python-dotenv wikipedia tiktoken \\\n",
        "    langchain-huggingface sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "SIOc-bIaj_0y"
      },
      "outputs": [],
      "source": [
        "from typing import List, TypedDict, Annotated\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "from IPython.display import Image, display, HTML, Markdown\n",
        "from astrapy import DataAPIClient\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "KgwiRuhMlwcu"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_classic.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "U_4-ZQeLRE28"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = userdata.get(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "ASTRA_DB_ID = userdata.get(\"ASTRA_DB_ID\")\n",
        "ASTRA_DB_API_ENDPOINT = f\"https://{ASTRA_DB_ID}-us-east1.apps.astra.datastax.com\"\n",
        "groq_api_key = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AstraDB Connection"
      ],
      "metadata": {
        "id": "M9vIKDlYLd83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR0KPYLwmSu0",
        "outputId": "8b7b3dd5-a41f-457a-df52-d97a63a97c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database configured\n",
            "Embeddings model loaded\n"
          ]
        }
      ],
      "source": [
        "# If and database and collection is created on DataStax AstraDB, use .get(), otherwise use .create_database() and .create_collection()\n",
        "client = DataAPIClient(ASTRA_DB_APPLICATION_TOKEN)\n",
        "database = client.get_database(ASTRA_DB_API_ENDPOINT)\n",
        "collection = database.get_collection(\"langgraph_react_demo\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"Database configured\")\n",
        "print(\"Embeddings model loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXmwsbQim2ju"
      },
      "source": [
        "## Populating Vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8aOn7sSDao",
        "outputId": "db64ca2f-63e5-4ad5-c6d2-eb906d77af44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3 documents\n"
          ]
        }
      ],
      "source": [
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "print(f\"Loaded {len(docs_list)} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z65Zq4_vnl8p",
        "outputId": "177f72ca-2f75-4594-ab32-1d029facbb13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 88 chunks\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=500, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "print(f\"Created {len(doc_splits)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCfJCQMInnK4",
        "outputId": "8dd2d9e4-ab24-4608-8dec-800a80934818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 88 documents into AstraDB\n"
          ]
        }
      ],
      "source": [
        "documents_to_insert = [\n",
        "    {\n",
        "        \"_id\": str(i),\n",
        "        \"content\": doc.page_content,\n",
        "        \"metadata\": doc.metadata,\n",
        "        \"$vector\": embeddings.embed_query(doc.page_content),\n",
        "    }\n",
        "    for i, doc in enumerate(doc_splits)\n",
        "]\n",
        "\n",
        "collection.insert_many(documents_to_insert)\n",
        "print(f\"Inserted {len(doc_splits)} documents into AstraDB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Creation"
      ],
      "metadata": {
        "id": "bL522tWDL8gq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "yqQwTGf2zECt"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "def vector_store_search(query: str) -> str:\n",
        "\n",
        "    query_embedding = embeddings.embed_query(query)\n",
        "    results = collection.find(\n",
        "        sort={\"$vector\": query_embedding},\n",
        "        limit=3,\n",
        "        include_similarity=True\n",
        "    )\n",
        "\n",
        "    documents = []\n",
        "    for result in results:\n",
        "        documents.append(result['content'])\n",
        "\n",
        "    return \"\\n\\n---\\n\\n\".join(documents)\n",
        "\n",
        "class VectorStoreSearchInput(BaseModel):\n",
        "    query: str = Field(description=\"The query string to search for in the vector store.\")\n",
        "\n",
        "vector_tool = Tool(\n",
        "    name=\"VectorStoreSearch\",\n",
        "    func=vector_store_search,\n",
        "    description=\"Search the vector store for information about AI agents, prompt engineering, and adversarial attacks. Use this for technical AI topics.\",\n",
        "    args_schema=VectorStoreSearchInput\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "iXjrcILH7mPL"
      },
      "outputs": [],
      "source": [
        "def wikipedia_search(query: str) -> str:\n",
        "\n",
        "    api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
        "    try:\n",
        "        result = api_wrapper.run(query)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Wikipedia search failed: {str(e)}\"\n",
        "\n",
        "class WikiSearchInput(BaseModel):\n",
        "    query: str = Field(description=\"The query string to search from Wikipedia\")\n",
        "\n",
        "wiki_tool = Tool(\n",
        "    name=\"WikipediaSearch\",\n",
        "    func=wikipedia_search,\n",
        "    description=\"Search Wikipedia for general knowledge questions about people, places, events, and other topics.\",\n",
        "    args_schema=WikiSearchInput\n",
        ")\n",
        "\n",
        "tools = [vector_tool, wiki_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoBl_GMK7xQ3"
      },
      "source": [
        "# LangChain Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVW2Cu7-7wnQ",
        "outputId": "56b7433c-35dd-4030-ff75-0d79af1ce419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain agent created\n"
          ]
        }
      ],
      "source": [
        "llm = ChatGroq(api_key=groq_api_key, model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful AI assistant with access to tools.\n",
        "    You have access to:\n",
        "    - VectorStoreSearch: For questions about AI agents, prompt engineering, and adversarial attacks\n",
        "    - WikipediaQueryRun: For general knowledge questions\n",
        "\n",
        "    Think carefully about which tool to use for each question. You can use multiple tools if needed.\n",
        "    Provide clear, concise answers based on the information you retrieve.\"\"\"),\n",
        "\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=5,\n",
        "    return_intermediate_steps=True\n",
        ")\n",
        "\n",
        "print(\"LangChain agent created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph Agent"
      ],
      "metadata": {
        "id": "5kSBOmfB89Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()\n",
        "\n",
        "graph_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "print(\"LangGraph agent with checkpoint\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoKmv7jy85EE",
        "outputId": "0942f6fa-6ce8-4dd3-83b3-0238a02d4cb9"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraph agent with checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-181701143.py:3: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  graph_agent = create_react_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    display(Image(graph_agent.get_graph().draw_mermaid_png()))\n",
        "\n",
        "except Exception as e:\n",
        "\n",
        "    print(f\"Graph visualization error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "SebA8n7w9J9G",
        "outputId": "637eacf2-fe76-479a-d040-bb58d2d2b9a0"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Agent Execution"
      ],
      "metadata": {
        "id": "r4m8pChhMA22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"LANGCHAIN AGENT EXECUTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nQUERY: What are the types of agent memory?\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"What are the various types of agent memory?\"})\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"EXECUTION TRACEBACK\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, step in enumerate(result['intermediate_steps'], 1):\n",
        "    action, observation = step\n",
        "    print(f\"\\nStep {i}:\")\n",
        "    print(f\"  Tool: {action.tool}\")\n",
        "    print(f\"  Input: {action.tool_input}\")\n",
        "    print(f\"  Output Preview: {observation[:150]}...\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"FINAL OUTPUT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{result['output']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEG4Wmqx9SSK",
        "outputId": "36f773f3-50ff-4bff-98a6-c7d4c14af136"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "LANGCHAIN AGENT EXECUTION\n",
            "================================================================================\n",
            "\n",
            "QUERY: What are the types of agent memory?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `VectorStoreSearch` with `{'query': 'types of agent memory'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3minquired about current trends in anticancer drug discovery;\n",
            "selected a target;\n",
            "requested a scaffold targeting these compounds;\n",
            "Once the compound was identified, the model attempted its synthesis.\n",
            "\n",
            "They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
            "Generative Agents Simulation#\n",
            "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
            "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
            "\n",
            "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided by the agent.\n",
            "- Inter-agent communication can trigger new natural language statements.\n",
            "\n",
            "\n",
            "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
            "\n",
            "Recency: recent events have higher scores\n",
            "Importance: distinguish mundane from core memories. Ask LM directly.\n",
            "Relevance: based on how related it is to the current situation / query.\n",
            "\n",
            "\n",
            "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
            "\n",
            "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
            "\n",
            "\n",
            "Planning & Reacting: translate the reflections and the environment information into actions\n",
            "\n",
            "---\n",
            "\n",
            "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Overview of a LLM-powered autonomous agent system.\n",
            "\n",
            "---\n",
            "\n",
            "LLM Powered Autonomous Agents | Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "|\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Posts\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Archive\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tags\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FAQ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "\n",
            "\n",
            "Agent System Overview\n",
            "\n",
            "Component One: Planning\n",
            "\n",
            "Task Decomposition\n",
            "\n",
            "Self-Reflection\n",
            "\n",
            "\n",
            "Component Two: Memory\n",
            "\n",
            "Types of Memory\n",
            "\n",
            "Maximum Inner Product Search (MIPS)\n",
            "\n",
            "\n",
            "Component Three: Tool Use\n",
            "\n",
            "Case Studies\n",
            "\n",
            "Scientific Discovery Agent\n",
            "\n",
            "Generative Agents Simulation\n",
            "\n",
            "Proof-of-Concept Examples\n",
            "\n",
            "\n",
            "Challenges\n",
            "\n",
            "Citation\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview#\n",
            "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
            "\n",
            "Planning\n",
            "\n",
            "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
            "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
            "\n",
            "\n",
            "Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
            "\n",
            "\n",
            "Tool use\u001b[0m\u001b[32;1m\u001b[1;3mThe various types of agent memory include:\n",
            "\n",
            "1. Short-term memory: utilized through in-context learning, as seen in Prompt Engineering.\n",
            "2. Long-term memory: provides the capability to retain and recall information over extended periods, often leveraging an external vector store and fast retrieval.\n",
            "3. Memory stream: a long-term memory module that records a comprehensive list of agents' experiences in natural language.\n",
            "\n",
            "Additionally, the reflection mechanism synthesizes memories into higher-level inferences over time, guiding the agent's future behavior.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EXECUTION TRACEBACK\n",
            "================================================================================\n",
            "\n",
            "Step 1:\n",
            "  Tool: VectorStoreSearch\n",
            "  Input: {'query': 'types of agent memory'}\n",
            "  Output Preview: inquired about current trends in anticancer drug discovery;\n",
            "selected a target;\n",
            "requested a scaffold targeting these compounds;\n",
            "Once the compound was i...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FINAL OUTPUT\n",
            "================================================================================\n",
            "\n",
            "The various types of agent memory include:\n",
            "\n",
            "1. Short-term memory: utilized through in-context learning, as seen in Prompt Engineering.\n",
            "2. Long-term memory: provides the capability to retain and recall information over extended periods, often leveraging an external vector store and fast retrieval.\n",
            "3. Memory stream: a long-term memory module that records a comprehensive list of agents' experiences in natural language.\n",
            "\n",
            "Additionally, the reflection mechanism synthesizes memories into higher-level inferences over time, guiding the agent's future behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph Agent Execution"
      ],
      "metadata": {
        "id": "DIVOK9E_MHgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"LANGGRAPH AGENT EXECUTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nQUERY: Who is Shah Rukh Khan?\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n\")\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"test-1\"}}\n",
        "\n",
        "messages_collected = []\n",
        "for chunk in graph_agent.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Who is Shah Rukh Khan?\")]},\n",
        "    config,\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    messages_collected.append(chunk[\"messages\"][-1])\n",
        "    chunk[\"messages\"][-1].pretty_print()\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"GRAPH STATE: {len(messages_collected)} messages in conversation\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf46p4vX-V7l",
        "outputId": "f7b3838e-b56b-4435-a673-4e470a550b79"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "LANGGRAPH AGENT EXECUTION\n",
            "================================================================================\n",
            "\n",
            "QUERY: Who is Shah Rukh Khan?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who is Shah Rukh Khan?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  WikipediaSearch (tgwfcjttc)\n",
            " Call ID: tgwfcjttc\n",
            "  Args:\n",
            "    query: Shah Rukh Khan\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: WikipediaSearch\n",
            "\n",
            "Page: Shah Rukh Khan\n",
            "Summary: Shah Rukh Khan (pronounced [ˈʃaːɦɾʊx xäːn] ; born as Shahrukh Khan on 2 November 1965), popularly known by the initials SRK, is an Indian actor and film producer renowned for his work in Hindi cinema. Referred to in the media as the \"Baadshah of Bollywood\" and \"King Khan\", he has appeared in more than 100 films and earned numerous accolades, including a National Film Award and 15 Filmfare Awards. He has been awarded the Padma Shri by the Government of India, as well\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Shah Rukh Khan is a renowned Indian actor and film producer known for his work in Hindi cinema, often referred to as the \"Baadshah of Bollywood\" and \"King Khan\". He has appeared in over 100 films and received numerous accolades, including a National Film Award and 15 Filmfare Awards.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "GRAPH STATE: 4 messages in conversation\n",
            "================================================================================\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi Turn Conversation with LangGraph"
      ],
      "metadata": {
        "id": "hsJ877J2MNHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"MULTI-TURN CONVERSATION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n\")\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}\n",
        "\n",
        "questions = [\n",
        "    \"What is an AI agent?\",\n",
        "    \"What tools can it use?\",\n",
        "    \"How does memory work in agents?\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(questions, 1):\n",
        "    print(f\"Turn {i}\")\n",
        "    print(\"-\"*80)\n",
        "    print(f\"USER: {question}\\n\")\n",
        "\n",
        "    step_count = 0\n",
        "    for chunk in graph_agent.stream(\n",
        "        {\"messages\": [HumanMessage(content=question)]},\n",
        "        config,\n",
        "        stream_mode=\"values\"\n",
        "    ):\n",
        "        step_count += 1\n",
        "        chunk[\"messages\"][-1].pretty_print()\n",
        "\n",
        "    print(f\"\\nGraph executed {step_count} steps\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWnR-wQOFy0T",
        "outputId": "7ef29b5d-8948-4d87-c303-3505befa322a"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "MULTI-TURN CONVERSATION\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Turn 1\n",
            "--------------------------------------------------------------------------------\n",
            "USER: What is an AI agent?\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is an AI agent?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  VectorStoreSearch (tzttbd49r)\n",
            " Call ID: tzttbd49r\n",
            "  Args:\n",
            "    query: AI agent\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: VectorStoreSearch\n",
            "\n",
            "LLM Powered Autonomous Agents | Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "|\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Posts\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Archive\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tags\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FAQ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "\n",
            "\n",
            "Agent System Overview\n",
            "\n",
            "Component One: Planning\n",
            "\n",
            "Task Decomposition\n",
            "\n",
            "Self-Reflection\n",
            "\n",
            "\n",
            "Component Two: Memory\n",
            "\n",
            "Types of Memory\n",
            "\n",
            "Maximum Inner Product Search (MIPS)\n",
            "\n",
            "\n",
            "Component Three: Tool Use\n",
            "\n",
            "Case Studies\n",
            "\n",
            "Scientific Discovery Agent\n",
            "\n",
            "Generative Agents Simulation\n",
            "\n",
            "Proof-of-Concept Examples\n",
            "\n",
            "\n",
            "Challenges\n",
            "\n",
            "Citation\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview#\n",
            "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
            "\n",
            "Planning\n",
            "\n",
            "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
            "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
            "\n",
            "\n",
            "Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
            "\n",
            "\n",
            "Tool use\n",
            "\n",
            "---\n",
            "\n",
            "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Overview of a LLM-powered autonomous agent system.\n",
            "\n",
            "---\n",
            "\n",
            "Planning is essentially in order to optimize believability at the moment vs in time.\n",
            "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
            "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
            "Environment information is present in a tree structure.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The generative agent architecture. (Image source: Park et al. 2023)\n",
            "\n",
            "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
            "Proof-of-Concept Examples#\n",
            "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
            "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
            "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
            "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. {{user-provided goal 1}}\n",
            "2. {{user-provided goal 2}}\n",
            "3. ...\n",
            "4. ...\n",
            "5. ...\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "5. Use subprocesses for commands that will not terminate within a few minutes\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "An AI agent is a system that uses a large language model (LLM) as its core controller, enabling it to perform tasks autonomously. It has several key components, including planning, memory, and tool use. The agent can break down complex tasks into smaller subgoals, reflect on its past actions, and learn from its mistakes. It also has the ability to retain and recall information over extended periods using external vector stores. Additionally, AI agents can call external APIs to access extra information and perform tasks such as code execution. Examples of AI agents include AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the potential of LLMs as powerful general problem solvers.\n",
            "\n",
            "Graph executed 4 steps\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Turn 2\n",
            "--------------------------------------------------------------------------------\n",
            "USER: What tools can it use?\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What tools can it use?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  VectorStoreSearch (v88pjkhn7)\n",
            " Call ID: v88pjkhn7\n",
            "  Args:\n",
            "    query: AI agent tool use\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: VectorStoreSearch\n",
            "\n",
            "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Overview of a LLM-powered autonomous agent system.\n",
            "\n",
            "---\n",
            "\n",
            "LLM Powered Autonomous Agents | Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "|\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Posts\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Archive\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tags\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FAQ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "\n",
            "\n",
            "Agent System Overview\n",
            "\n",
            "Component One: Planning\n",
            "\n",
            "Task Decomposition\n",
            "\n",
            "Self-Reflection\n",
            "\n",
            "\n",
            "Component Two: Memory\n",
            "\n",
            "Types of Memory\n",
            "\n",
            "Maximum Inner Product Search (MIPS)\n",
            "\n",
            "\n",
            "Component Three: Tool Use\n",
            "\n",
            "Case Studies\n",
            "\n",
            "Scientific Discovery Agent\n",
            "\n",
            "Generative Agents Simulation\n",
            "\n",
            "Proof-of-Concept Examples\n",
            "\n",
            "\n",
            "Challenges\n",
            "\n",
            "Citation\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview#\n",
            "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
            "\n",
            "Planning\n",
            "\n",
            "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
            "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
            "\n",
            "\n",
            "Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
            "\n",
            "\n",
            "Tool use\n",
            "\n",
            "---\n",
            "\n",
            "Planning is essentially in order to optimize believability at the moment vs in time.\n",
            "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
            "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
            "Environment information is present in a tree structure.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The generative agent architecture. (Image source: Park et al. 2023)\n",
            "\n",
            "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
            "Proof-of-Concept Examples#\n",
            "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
            "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
            "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
            "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. {{user-provided goal 1}}\n",
            "2. {{user-provided goal 2}}\n",
            "3. ...\n",
            "4. ...\n",
            "5. ...\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "5. Use subprocesses for commands that will not terminate within a few minutes\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "An AI agent can use various tools, including external APIs, to access extra information, perform code execution, and retrieve proprietary information sources. These tools enable the agent to gather current information, execute tasks, and leverage external resources to enhance its capabilities.\n",
            "\n",
            "Graph executed 4 steps\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Turn 3\n",
            "--------------------------------------------------------------------------------\n",
            "USER: How does memory work in agents?\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How does memory work in agents?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  VectorStoreSearch (wbc6xavav)\n",
            " Call ID: wbc6xavav\n",
            "  Args:\n",
            "    query: AI agent memory\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: VectorStoreSearch\n",
            "\n",
            "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Overview of a LLM-powered autonomous agent system.\n",
            "\n",
            "---\n",
            "\n",
            "LLM Powered Autonomous Agents | Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "|\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Posts\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Archive\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tags\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FAQ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "\n",
            "\n",
            "Agent System Overview\n",
            "\n",
            "Component One: Planning\n",
            "\n",
            "Task Decomposition\n",
            "\n",
            "Self-Reflection\n",
            "\n",
            "\n",
            "Component Two: Memory\n",
            "\n",
            "Types of Memory\n",
            "\n",
            "Maximum Inner Product Search (MIPS)\n",
            "\n",
            "\n",
            "Component Three: Tool Use\n",
            "\n",
            "Case Studies\n",
            "\n",
            "Scientific Discovery Agent\n",
            "\n",
            "Generative Agents Simulation\n",
            "\n",
            "Proof-of-Concept Examples\n",
            "\n",
            "\n",
            "Challenges\n",
            "\n",
            "Citation\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview#\n",
            "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
            "\n",
            "Planning\n",
            "\n",
            "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
            "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
            "\n",
            "\n",
            "Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
            "\n",
            "\n",
            "Tool use\n",
            "\n",
            "---\n",
            "\n",
            "Planning is essentially in order to optimize believability at the moment vs in time.\n",
            "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
            "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
            "Environment information is present in a tree structure.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The generative agent architecture. (Image source: Park et al. 2023)\n",
            "\n",
            "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
            "Proof-of-Concept Examples#\n",
            "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
            "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
            "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
            "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. {{user-provided goal 1}}\n",
            "2. {{user-provided goal 2}}\n",
            "3. ...\n",
            "4. ...\n",
            "5. ...\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "5. Use subprocesses for commands that will not terminate within a few minutes\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "In AI agents, memory works through two primary components: short-term memory and long-term memory. Short-term memory refers to the agent's ability to learn from in-context information, utilizing the model's capacity for prompt engineering. Long-term memory, on the other hand, enables the agent to retain and recall information over extended periods by leveraging an external vector store and fast retrieval mechanisms. This allows the agent to access and utilize a vast amount of information, even if it's not present in the initial training data.\n",
            "\n",
            "Graph executed 4 steps\n",
            "================================================================================\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unified Calling\n",
        "\n",
        "def ask_agent(question: str, use_langgraph=True, thread_id=\"default\"):\n",
        "\n",
        "    #thread_id: Thread ID for conversation memory\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"QUERY: {question}\")\n",
        "    print(\"=\" * 80)\n",
        "    print( \"\\n\")\n",
        "\n",
        "    if use_langgraph:\n",
        "        print(\"[Using LangGraph Agent with Memory]\\n\")\n",
        "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "        step_count = 0\n",
        "        tool_calls = []\n",
        "\n",
        "        for chunk in graph_agent.stream(\n",
        "            {\"messages\": [HumanMessage(content=question)]},\n",
        "            config,\n",
        "            stream_mode=\"values\"\n",
        "        ):\n",
        "            step_count += 1\n",
        "            msg = chunk[\"messages\"][-1]\n",
        "\n",
        "            # Track tool calls\n",
        "            if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "                for tc in msg.tool_calls:\n",
        "                    tool_calls.append(tc['name'])\n",
        "\n",
        "            msg.pretty_print()\n",
        "\n",
        "        print(f\"\\n{'─'*80}\")\n",
        "        print(f\"Graph Steps: {step_count} | Tools Used: {', '.join(set(tool_calls)) if tool_calls else 'None'}\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        print(\"[Using LangChain Agent]\\n\")\n",
        "        result = agent_executor.invoke({\"input\": question})\n",
        "\n",
        "        print(\"\\nExecution Trace:\")\n",
        "        print(\"=\"*80)\n",
        "        for i, step in enumerate(result['intermediate_steps'], 1):\n",
        "            action, observation = step\n",
        "            print(f\"Step {i}: {action.tool}\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"=\" * 80)\n",
        "        print(\"ANSWER\")\n",
        "        print(\"=\"*80)\n",
        "        print(result['output'])\n",
        "        print(\"=\" * 80)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "s5PfB76bGj-s"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_agent(\"Explain the different types of prompt engineering techniques\", use_langgraph=True)\n",
        "ask_agent(\"Who is Albert Einstein?\", use_langgraph=True)\n",
        "ask_agent(\"Compare adversarial attacks with prompt engineering methods\", use_langgraph=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQzz0IUvHL1H",
        "outputId": "95b21aeb-5dcf-4885-b4ae-409b229400f2"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "QUERY: Explain the different types of prompt engineering techniques\n",
            "================================================================================\n",
            "\n",
            "\n",
            "[Using LangGraph Agent with Memory]\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Explain the different types of prompt engineering techniques\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  VectorStoreSearch (chgjpp1et)\n",
            " Call ID: chgjpp1et\n",
            "  Args:\n",
            "    query: prompt engineering techniques\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: VectorStoreSearch\n",
            "\n",
            "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
            "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
            "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
            "Basic Prompting#\n",
            "Zero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\n",
            "Zero-Shot#\n",
            "Zero-shot learning is to simply feed the task text to the model and ask for results.\n",
            "(All the sentiment analysis examples are from SST-2)\n",
            "Text: i'll bet the video game is a lot more fun than the film.\n",
            "Sentiment:\n",
            "Few-shot#\n",
            "Few-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\n",
            "Text: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\n",
            "Sentiment: positive\n",
            "\n",
            "---\n",
            "\n",
            "Weng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.\n",
            "\n",
            "Or\n",
            "@article{weng2023prompt,\n",
            "  title   = \"Prompt Engineering\",\n",
            "  author  = \"Weng, Lilian\",\n",
            "  journal = \"lilianweng.github.io\",\n",
            "  year    = \"2023\",\n",
            "  month   = \"Mar\",\n",
            "  url     = \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\n",
            "}\n",
            "Useful Resources#\n",
            "\n",
            "OpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently.\n",
            "LangChain, a library for combining language models with other components to build applications.\n",
            "Prompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.\n",
            "learnprompting.org\n",
            "PromptPerfect\n",
            "Semantic Kernel\n",
            "\n",
            "---\n",
            "\n",
            "Prompt Engineering | Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lil'Log\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "|\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Posts\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Archive\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tags\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FAQ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      Prompt Engineering\n",
            "    \n",
            "Date: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "\n",
            "\n",
            "Basic Prompting\n",
            "\n",
            "Zero-Shot\n",
            "\n",
            "Few-shot\n",
            "\n",
            "Tips for Example Selection\n",
            "\n",
            "Tips for Example Ordering\n",
            "\n",
            "\n",
            "\n",
            "Instruction Prompting\n",
            "\n",
            "Self-Consistency Sampling\n",
            "\n",
            "Chain-of-Thought (CoT)\n",
            "\n",
            "Types of CoT prompts\n",
            "\n",
            "Tips and Extensions\n",
            "\n",
            "\n",
            "Automatic Prompt Design\n",
            "\n",
            "Augmented Language Models\n",
            "\n",
            "Retrieval\n",
            "\n",
            "Programming Language\n",
            "\n",
            "External APIs\n",
            "\n",
            "\n",
            "Citation\n",
            "\n",
            "Useful Resources\n",
            "\n",
            "References\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Prompt engineering techniques include zero-shot and few-shot learning, instruction prompting, self-consistency sampling, and chain-of-thought (CoT) prompting. Zero-shot learning involves feeding the task text to the model and asking for results, while few-shot learning presents a set of high-quality demonstrations to help the model understand human intention. Instruction prompting involves providing explicit instructions to the model, and self-consistency sampling involves sampling multiple outputs from the model to improve accuracy. CoT prompting involves generating a series of intermediate steps to arrive at a final answer. Additionally, there are techniques for automatic prompt design, augmented language models, retrieval, and using external APIs.\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Graph Steps: 4 | Tools Used: VectorStoreSearch\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUERY: Who is Albert Einstein?\n",
            "================================================================================\n",
            "\n",
            "\n",
            "[Using LangGraph Agent with Memory]\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who is Albert Einstein?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  WikipediaSearch (fe5j7rmpj)\n",
            " Call ID: fe5j7rmpj\n",
            "  Args:\n",
            "    query: Albert Einstein\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: WikipediaSearch\n",
            "\n",
            "Page: Albert Einstein\n",
            "Summary: Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist best known for developing the theory of relativity. Einstein also made important contributions to quantum theory. His mass–energy equivalence formula E = mc2, which arises from special relativity, has been called \"the world's most famous equation\". He received the 1921 Nobel Prize in Physics for \"his services to theoretical physics, and especially for his discovery of the law of\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Albert Einstein was a German-born theoretical physicist who developed the theory of relativity and made significant contributions to quantum theory. He is best known for his mass-energy equivalence formula E = mc2 and received the 1921 Nobel Prize in Physics for his services to theoretical physics.\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Graph Steps: 4 | Tools Used: WikipediaSearch\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUERY: Compare adversarial attacks with prompt engineering methods\n",
            "================================================================================\n",
            "\n",
            "\n",
            "[Using LangChain Agent]\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `VectorStoreSearch` with `{'query': 'adversarial attacks vs prompt engineering'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mOne simple and intuitive way to defend the model against adversarial attacks is to explicitly instruct model to be responsible, not generating harmful content (Xie et al. 2023). It can largely reduce the success rate of jailbreak attacks, but has side effects for general model quality due to the model acting more conservatively (e.g. for creative writing) or incorrectly interpreting the instruction under some scenarios (e.g. safe-unsafe classification).\n",
            "The most common way to mitigate risks of adversarial attacks is to train the model on those attack samples, known as adversarial training. It is considered as the strongest defense but leading to tradeoff between robustness and model performance. In an experiment by Jain et al. 2023, they tested two adversarial training setups: (1) run gradient descent on harmful prompts paired with \"I'm sorry. As a ...\" response; (2) run one descent step on a refusal response and an ascend step on a red-team bad response per training step. The method (2) ends up being quite useless because the model generation quality degrades a lot, while the drop in attack success rate is tiny.\n",
            "White-box attacks often lead to nonsensical adversarial prompts and thus they can be detected by examining perplexity. Of course, a white-box attack can directly bypass this by explicitly optimizing for lower perplexity, such as UAT-LM, a variation of UAT. However, there is a tradeoff and it can lead to lower attack success rate.\n",
            "\n",
            "\n",
            "Perplexity filter can block attacks by [Zou et al. (2023)](https://arxiv.org/abs/2307.15043). \"PPL Passed\" and \"PPL Window Passed\" are the rates at which harmful prompts with an adversarial suffix bypass the filter without detection. The lower the pass rate the better the filter is. (Image source: Jain et al. 2023)\n",
            "\n",
            "Jain et al. 2023 also tested methods of preprocessing text inputs to remove adversarial modifications while semantic meaning remains.\n",
            "\n",
            "---\n",
            "\n",
            "Paraphrase: Use LLM to paraphrase input text, which can may cause small impacts on downstream task performance.\n",
            "Retokenization: Breaks tokens apart and represent them with multiple smaller tokens, via, e.g. BPE-dropout (drop random p% tokens). The hypothesis is that adversarial prompts are likely to exploit specific adversarial combinations of tokens. This does help degrade the attack success rate but is limited, e.g. 90+% down to 40%.\n",
            "\n",
            "Citation#\n",
            "Cited as:\n",
            "\n",
            "Weng, Lilian. (Oct 2023). “Adversarial Attacks on LLMs”. Lil’Log. https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/.\n",
            "\n",
            "---\n",
            "\n",
            "Or\n",
            "@article{weng2023attack,\n",
            "  title   = \"Adversarial Attacks on LLMs\",\n",
            "  author  = \"Weng, Lilian\",\n",
            "  journal = \"lilianweng.github.io\",\n",
            "  year    = \"2023\",\n",
            "  month   = \"Oct\",\n",
            "  url     = \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\"\n",
            "}\n",
            "References#\n",
            "[1] Madry et al. “Towards Deep Learning Models Resistant to Adversarial Attacks”. ICLR 2018.\n",
            "[2] Ribeiro et al. “Semantically equivalent adversarial rules for debugging NLP models”. ACL 2018.\n",
            "[3] Guo et al. “Gradient-based adversarial attacks against text transformers”. arXiv preprint arXiv:2104.13733 (2021).\n",
            "[4] Ebrahimi et al. “HotFlip: White-Box Adversarial Examples for Text Classification”. ACL 2018.\n",
            "[5] Wallace et al. “Universal Adversarial Triggers for Attacking and Analyzing NLP.” EMNLP-IJCNLP 2019. | code\n",
            "[6] Mehrabi et al. “Robust Conversational Agents against Imperceptible Toxicity Triggers.” NAACL 2022.\n",
            "[7] Zou et al. “Universal and Transferable Adversarial Attacks on Aligned Language Models.” arXiv preprint arXiv:2307.15043 (2023)\n",
            "[8] Deng et al. “RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning.” EMNLP 2022.\n",
            "[9] Jin et al. “Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment.” AAAI 2020.\n",
            "[10] Li et al. “BERT-Attack: Adversarial Attack Against BERT Using BERT.” EMNLP 2020.\u001b[0m\u001b[32;1m\u001b[1;3mAdversarial attacks and prompt engineering are two related concepts in the field of natural language processing (NLP) and large language models (LLMs). Adversarial attacks refer to the techniques used to manipulate or deceive LLMs into producing undesirable or harmful outputs. Prompt engineering, on the other hand, involves designing and optimizing input prompts to elicit specific or desired responses from LLMs.\n",
            "\n",
            "While both concepts deal with the interaction between humans and LLMs, they have different goals and approaches. Adversarial attacks aim to exploit vulnerabilities in LLMs, whereas prompt engineering seeks to improve the performance and controllability of LLMs.\n",
            "\n",
            "Some common methods used to defend against adversarial attacks include adversarial training, perplexity filters, and input preprocessing techniques such as paraphrasing and retokenization. These methods can help mitigate the risks associated with adversarial attacks, but they may also have trade-offs in terms of model performance and quality.\n",
            "\n",
            "In contrast, prompt engineering involves techniques such as optimizing discrete text prompts using reinforcement learning (RLPrompt) and designing prompts that are more effective at eliciting desired responses from LLMs.\n",
            "\n",
            "Overall, understanding the differences and similarities between adversarial attacks and prompt engineering can help researchers and practitioners develop more robust and controllable LLMs.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Execution Trace:\n",
            "================================================================================\n",
            "Step 1: VectorStoreSearch\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ANSWER\n",
            "================================================================================\n",
            "Adversarial attacks and prompt engineering are two related concepts in the field of natural language processing (NLP) and large language models (LLMs). Adversarial attacks refer to the techniques used to manipulate or deceive LLMs into producing undesirable or harmful outputs. Prompt engineering, on the other hand, involves designing and optimizing input prompts to elicit specific or desired responses from LLMs.\n",
            "\n",
            "While both concepts deal with the interaction between humans and LLMs, they have different goals and approaches. Adversarial attacks aim to exploit vulnerabilities in LLMs, whereas prompt engineering seeks to improve the performance and controllability of LLMs.\n",
            "\n",
            "Some common methods used to defend against adversarial attacks include adversarial training, perplexity filters, and input preprocessing techniques such as paraphrasing and retokenization. These methods can help mitigate the risks associated with adversarial attacks, but they may also have trade-offs in terms of model performance and quality.\n",
            "\n",
            "In contrast, prompt engineering involves techniques such as optimizing discrete text prompts using reinforcement learning (RLPrompt) and designing prompts that are more effective at eliciting desired responses from LLMs.\n",
            "\n",
            "Overall, understanding the differences and similarities between adversarial attacks and prompt engineering can help researchers and practitioners develop more robust and controllable LLMs.\n",
            "================================================================================\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_conversation_state(thread_id: str):\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    state = graph_agent.get_state(config)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"CONVERSATION STATE: Thread '{thread_id}'\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    if state and hasattr(state, 'values') and 'messages' in state.values:\n",
        "        messages = state.values['messages']\n",
        "        print(f\"Total messages in thread: {len(messages)}\\n\")\n",
        "\n",
        "        for i, msg in enumerate(messages, 1):\n",
        "            role = type(msg).__name__.replace('Message', '')\n",
        "            content_preview = str(msg.content)[:100] + \"...\" if len(str(msg.content)) > 100 else str(msg.content)\n",
        "            print(f\"{i}. [{role}] {content_preview}\")\n",
        "    else:\n",
        "        print(\"No conversation history found\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\n\")\n",
        "\n",
        "visualize_conversation_state(\"state-test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icwkLkBWHN-z",
        "outputId": "39b0b0ac-6d16-4d92-d286-9d52ac13037d"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "CONVERSATION STATE: Thread 'state-test'\n",
            "================================================================================\n",
            "\n",
            "\n",
            "No conversation history found\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH10caS3krBd"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}